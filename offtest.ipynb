{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping line 1653429: expected 206 fields, saw 235\n",
      "\n",
      "C:\\Users\\maxin\\AppData\\Local\\Temp\\ipykernel_14872\\1935691852.py:2: DtypeWarning: Columns (0,11,17,31,32,33,34,35,52,56,67,72) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  allbarcodes = pd.read_csv(\"C:\\\\Users\\\\maxin\\\\OneDrive\\\\Documents\\\\School\\\\fridgefindsdev\\\\opencvtesting\\\\en.openfoodfacts.org.products.csv\",\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code                 object\n",
      "url                  object\n",
      "creator              object\n",
      "created_t             int64\n",
      "created_datetime     object\n",
      "                     ...   \n",
      "inositol_100g       float64\n",
      "carnitine_100g      float64\n",
      "sulphate_100g       float64\n",
      "nitrate_100g        float64\n",
      "acidity_100g        float64\n",
      "Length: 206, dtype: object\n",
      "  code                                                url  creator  \\\n",
      "0   54  http://world-en.openfoodfacts.org/product/0000...  kiliweb   \n",
      "1   63  http://world-en.openfoodfacts.org/product/0000...  kiliweb   \n",
      "2  114  http://world-en.openfoodfacts.org/product/0000...  kiliweb   \n",
      "3    1  http://world-en.openfoodfacts.org/product/0000...      inf   \n",
      "4  105  http://world-en.openfoodfacts.org/product/0000...  kiliweb   \n",
      "\n",
      "    created_t      created_datetime  last_modified_t last_modified_datetime  \\\n",
      "0  1582569031  2020-02-24T18:30:31Z       1733085204   2024-12-01T20:33:24Z   \n",
      "1  1673620307  2023-01-13T14:31:47Z       1732913331   2024-11-29T20:48:51Z   \n",
      "2  1580066482  2020-01-26T19:21:22Z       1737247862   2025-01-19T00:51:02Z   \n",
      "3  1634745456  2021-10-20T15:57:36Z       1738543736   2025-02-03T00:48:56Z   \n",
      "4  1572117743  2019-10-26T19:22:23Z       1738073570   2025-01-28T14:12:50Z   \n",
      "\n",
      "   last_modified_by  last_updated_t last_updated_datetime  ...  \\\n",
      "0               NaN    1.736277e+09  2025-01-07T19:07:50Z  ...   \n",
      "1  insectproductadd    1.736257e+09  2025-01-07T13:29:48Z  ...   \n",
      "2      smoothie-app    1.737248e+09  2025-01-19T00:51:02Z  ...   \n",
      "3            maldan    1.738544e+09  2025-02-03T00:48:56Z  ...   \n",
      "4               NaN    1.738074e+09  2025-01-28T14:12:50Z  ...   \n",
      "\n",
      "  glycemic-index_100g water-hardness_100g choline_100g phylloquinone_100g  \\\n",
      "0                 NaN                 NaN          NaN                NaN   \n",
      "1                 NaN                 NaN          NaN                NaN   \n",
      "2                 NaN                 NaN          NaN                NaN   \n",
      "3                 NaN                 NaN          NaN                NaN   \n",
      "4                 NaN                 NaN          NaN                NaN   \n",
      "\n",
      "  beta-glucan_100g inositol_100g carnitine_100g sulphate_100g nitrate_100g  \\\n",
      "0              NaN           NaN            NaN           NaN          NaN   \n",
      "1              NaN           NaN            NaN           NaN          NaN   \n",
      "2              NaN           NaN            NaN           NaN          NaN   \n",
      "3              NaN           NaN            NaN           NaN          NaN   \n",
      "4              NaN           NaN            NaN           NaN          NaN   \n",
      "\n",
      "  acidity_100g  \n",
      "0          NaN  \n",
      "1          NaN  \n",
      "2          NaN  \n",
      "3          NaN  \n",
      "4          NaN  \n",
      "\n",
      "[5 rows x 206 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "allbarcodes = pd.read_csv(\"C:\\\\Users\\\\maxin\\\\OneDrive\\\\Documents\\\\School\\\\fridgefindsdev\\\\opencvtesting\\\\en.openfoodfacts.org.products.csv\",\n",
    "                          sep=\"\\t\", encoding=\"utf-8\", on_bad_lines='warn')\n",
    "print(allbarcodes.dtypes)\n",
    "print(allbarcodes.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [code, url, creator, created_t, created_datetime, last_modified_t, last_modified_datetime, last_modified_by, last_updated_t, last_updated_datetime, product_name, abbreviated_product_name, generic_name, quantity, packaging, packaging_tags, packaging_en, packaging_text, brands, brands_tags, categories, categories_tags, categories_en, origins, origins_tags, origins_en, manufacturing_places, manufacturing_places_tags, labels, labels_tags, labels_en, emb_codes, emb_codes_tags, first_packaging_code_geo, cities, cities_tags, purchase_places, stores, countries, countries_tags, countries_en, ingredients_text, ingredients_tags, ingredients_analysis_tags, allergens, allergens_en, traces, traces_tags, traces_en, serving_size, serving_quantity, no_nutrition_data, additives_n, additives, additives_tags, additives_en, nutriscore_score, nutriscore_grade, nova_group, pnns_groups_1, pnns_groups_2, food_groups, food_groups_tags, food_groups_en, states, states_tags, states_en, brand_owner, environmental_score_score, environmental_score_grade, nutrient_levels_tags, product_quantity, owner, data_quality_errors_tags, unique_scans_n, popularity_tags, completeness, last_image_t, last_image_datetime, main_category, main_category_en, image_url, image_small_url, image_ingredients_url, image_ingredients_small_url, image_nutrition_url, image_nutrition_small_url, energy-kj_100g, energy-kcal_100g, energy_100g, energy-from-fat_100g, fat_100g, saturated-fat_100g, butyric-acid_100g, caproic-acid_100g, caprylic-acid_100g, capric-acid_100g, lauric-acid_100g, myristic-acid_100g, palmitic-acid_100g, ...]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 206 columns]\n"
     ]
    }
   ],
   "source": [
    "data = allbarcodes.loc[allbarcodes['code'] == \"6281007063647\"]\n",
    "data.to_csv(\"outputtest.csv\",mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from pyzbar.pyzbar import decode\n",
    "import pandas as pd\n",
    "def detect_and_decode_barcode(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect barcodes in the grayscale image\n",
    "    barcodes = decode(gray)\n",
    "\n",
    "    # Loop over detected barcodes\n",
    "    for barcode in barcodes:\n",
    "        # Extract barcode data and type\n",
    "        barcode_data = barcode.data.decode(\"utf-8\")\n",
    "        barcode_type = barcode.type\n",
    "\n",
    "        # Print barcode data and type\n",
    "        print(\"Barcode Data:\", barcode_data)\n",
    "        print(\"Barcode Type:\", barcode_type)\n",
    "        \n",
    "        data = allbarcodes.loc[allbarcodes['code'] == str(barcode_data)]\n",
    "        data.to_csv(\"outputtest.csv\",mode='a', header=False)\n",
    "\n",
    "        # Draw a rectangle around the barcode\n",
    "        (x, y, w, h) = barcode.rect\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "        # Put barcode data and type on the image\n",
    "        cv2.putText(image, f\"{barcode_data} ({barcode_type})\",\n",
    "                    (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barcode Data: 6281007063647\n",
      "Barcode Type: EAN13\n",
      "Barcode Data: 6281007063647\n",
      "Barcode Type: EAN13\n",
      "Barcode Data: 6281007063647\n",
      "Barcode Type: EAN13\n",
      "Barcode Data: 6281007063647\n",
      "Barcode Type: EAN13\n",
      "Barcode Data: 6281007063647\n",
      "Barcode Type: EAN13\n",
      "Barcode Data: 6281007063647\n",
      "Barcode Type: EAN13\n",
      "Barcode Data: 6281007063647\n",
      "Barcode Type: EAN13\n",
      "Barcode Data: 6281007063647\n",
      "Barcode Type: EAN13\n",
      "Barcode Data: 6281007063647\n",
      "Barcode Type: EAN13\n",
      "Barcode Data: 6281007063647\n",
      "Barcode Type: EAN13\n",
      "Barcode Data: 6281007063647\n",
      "Barcode Type: EAN13\n",
      "Barcode Data: 6281007063647\n",
      "Barcode Type: EAN13\n",
      "Barcode Data: 6281007063647\n",
      "Barcode Type: EAN13\n",
      "Barcode Data: 6281007063647\n",
      "Barcode Type: EAN13\n",
      "Barcode Data: 6281007063647\n",
      "Barcode Type: EAN13\n",
      "Barcode Data: 6281007063647\n",
      "Barcode Type: EAN13\n",
      "Barcode Data: 6281007063647\n",
      "Barcode Type: EAN13\n",
      "Barcode Data: 6281007063647\n",
      "Barcode Type: EAN13\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    #1\n",
    "    camera = cv2.VideoCapture(0)\n",
    "    ret, frame = camera.read()\n",
    "    #2\n",
    "    while ret:\n",
    "        ret, frame = camera.read()\n",
    "        frame = detect_and_decode_barcode(frame)\n",
    "        cv2.imshow('Barcode/QR code reader', frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "    #3\n",
    "    camera.release()\n",
    "    cv2.destroyAllWindows()\n",
    "#4\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maxin\\.cache\\openfoodfacts\\datasets\\en.openfoodfacts.org.products.csv.gz:  73%|███████▎  | 670M/914M [8:04:53<2:56:32, 24.1kB/s]\n"
     ]
    },
    {
     "ename": "ChunkedEncodingError",
     "evalue": "('Connection broken: IncompleteRead(702290462 bytes read, 255680034 more expected)', IncompleteRead(702290462 bytes read, 255680034 more expected))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIncompleteRead\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\urllib3\\response.py:710\u001b[0m, in \u001b[0;36mHTTPResponse._error_catcher\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 710\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    713\u001b[0m     \u001b[38;5;66;03m# FIXME: Ideally we'd like to include the url in the ReadTimeoutError but\u001b[39;00m\n\u001b[0;32m    714\u001b[0m     \u001b[38;5;66;03m# there is yet no clean way to get at it from this context.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\urllib3\\response.py:835\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    825\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    826\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menforce_content_length\n\u001b[0;32m    827\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength_remaining \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    833\u001b[0m             \u001b[38;5;66;03m# raised during streaming, so all calls with incorrect\u001b[39;00m\n\u001b[0;32m    834\u001b[0m             \u001b[38;5;66;03m# Content-Length are caught.\u001b[39;00m\n\u001b[1;32m--> 835\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp_bytes_read, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength_remaining)\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data:\n",
      "\u001b[1;31mIncompleteRead\u001b[0m: IncompleteRead(702290462 bytes read, 255680034 more expected)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mProtocolError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\requests\\models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    819\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 820\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    821\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\urllib3\\response.py:936\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m    935\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 936\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    938\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\urllib3\\response.py:907\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[0;32m    903\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m<\u001b[39m amt \u001b[38;5;129;01mand\u001b[39;00m data:\n\u001b[0;32m    904\u001b[0m     \u001b[38;5;66;03m# TODO make sure to initially read enough data to get past the headers\u001b[39;00m\n\u001b[0;32m    905\u001b[0m     \u001b[38;5;66;03m# For example, the GZ file header takes 10 bytes, we don't want to read\u001b[39;00m\n\u001b[0;32m    906\u001b[0m     \u001b[38;5;66;03m# it one byte at a time\u001b[39;00m\n\u001b[1;32m--> 907\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    908\u001b[0m     decoded_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decode(data, decode_content, flush_decoder)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\urllib3\\response.py:813\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    811\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 813\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_error_catcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    814\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfp_closed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\contextlib.py:155\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen\u001b[38;5;241m.\u001b[39mthrow(typ, value, traceback)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\urllib3\\response.py:727\u001b[0m, in \u001b[0;36mHTTPResponse._error_catcher\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (HTTPException, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    726\u001b[0m     \u001b[38;5;66;03m# This includes IncompleteRead.\u001b[39;00m\n\u001b[1;32m--> 727\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ProtocolError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection broken: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    729\u001b[0m \u001b[38;5;66;03m# If no exception is thrown, we should avoid cleaning up\u001b[39;00m\n\u001b[0;32m    730\u001b[0m \u001b[38;5;66;03m# unnecessarily.\u001b[39;00m\n",
      "\u001b[1;31mProtocolError\u001b[0m: ('Connection broken: IncompleteRead(702290462 bytes read, 255680034 more expected)', IncompleteRead(702290462 bytes read, 255680034 more expected))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mChunkedEncodingError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopenfoodfacts\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mopenfoodfacts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProductDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(dataset\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\openfoodfacts\\dataset.py:130\u001b[0m, in \u001b[0;36mProductDataset.__init__\u001b[1;34m(self, flavor, dataset_type, dataset_path, obsolete, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown dataset type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_suffix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 130\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_path \u001b[38;5;241m=\u001b[39m \u001b[43mget_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mflavor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobsolete\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobsolete\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\openfoodfacts\\dataset.py:81\u001b[0m, in \u001b[0;36mget_dataset\u001b[1;34m(flavor, dataset_type, force_download, download_newer, cache_dir, obsolete)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dataset_path\n\u001b[0;32m     80\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading dataset, saving it in \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, dataset_path)\n\u001b[1;32m---> 81\u001b[0m \u001b[43mdownload_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dataset_path\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\openfoodfacts\\utils\\__init__.py:201\u001b[0m, in \u001b[0;36mdownload_file\u001b[1;34m(url, output_path)\u001b[0m\n\u001b[0;32m    192\u001b[0m tmp_output_path \u001b[38;5;241m=\u001b[39m output_path\u001b[38;5;241m.\u001b[39mwith_name(output_path\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.part\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tmp_output_path\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f, tqdm\u001b[38;5;241m.\u001b[39mtqdm(\n\u001b[0;32m    194\u001b[0m     unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    195\u001b[0m     unit_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    199\u001b[0m     total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(r\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent-length\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m)),\n\u001b[0;32m    200\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m--> 201\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4096\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpbar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\requests\\models.py:822\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    821\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 822\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m DecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ContentDecodingError(e)\n",
      "\u001b[1;31mChunkedEncodingError\u001b[0m: ('Connection broken: IncompleteRead(702290462 bytes read, 255680034 more expected)', IncompleteRead(702290462 bytes read, 255680034 more expected))"
     ]
    }
   ],
   "source": [
    "import openfoodfacts\n",
    "dataset = openfoodfacts.ProductDataset(dataset_type=\"csv\")\n",
    "print(dataset.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
